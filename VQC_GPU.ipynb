{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b5dc21",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9c2eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as itr\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import torch as torch\n",
    "from torch import Tensor, manual_seed, is_tensor, LongTensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, Aer, execute, transpile, assemble, IBMQ\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter,ParameterVector\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.circuit.library import EfficientSU2, RealAmplitudes, ZZFeatureMap\n",
    "from qiskit.opflow.gradients import Gradient, NaturalGradient, QFI, Hessian\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from qiskit.algorithms.optimizers import SPSA, GradientDescent, QNSPSA, ADAM\n",
    "#from qiskit.tools.monitor import job_monitor\n",
    "\n",
    "\n",
    "from qiskit_machine_learning.runtime import TorchRuntimeClient, TorchRuntimeResult\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "COUNTER = 0\n",
    "DIR_val_train = \"Encode_data/amp_enc_data_set_trainning_values.csv\"\n",
    "DIR_cls_train = \"Encode_data/amp_enc_data_set_trainning_classes.csv\"\n",
    "\n",
    "DIR_val_test = \"Encode_data/amp_enc_data_set_test_values.csv\"\n",
    "DIR_cls_test = \"Encode_data/amp_enc_data_set_test_classes.csv\"\n",
    "\n",
    "quantum_instance = QuantumInstance(backend=Aer.get_backend('qasm_simulator'), shots=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9979cd69",
   "metadata": {},
   "source": [
    "# Create Data Set/Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb512d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encode(file):\n",
    "    \"\"\"\n",
    "     Funcao responsavel pelo encoding (amplitude)\n",
    "        Input :: \n",
    "        ### file : File dir\n",
    "        Output :: \n",
    "        #### data_enc : Valores para o encode (numpy array)\n",
    "    \"\"\"\n",
    "    return np.genfromtxt(file, delimiter=\";\")\n",
    "\n",
    "train_data = get_encode(DIR_val_train)\n",
    "train_data_T = Tensor(train_data)\n",
    "train_labels = np.genfromtxt(DIR_cls_train, delimiter=\";\")\n",
    "train_labels_T = Tensor(train_labels).reshape(len(train_labels)).long()\n",
    "\n",
    "# Test data points\n",
    "test_data = get_encode(DIR_val_test)\n",
    "test_data_T = Tensor(test_data)\n",
    "test_labels = np.genfromtxt(DIR_cls_test, delimiter=\";\")\n",
    "test_labels_T = Tensor(test_labels).reshape(len(test_labels)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom torch dataset class\n",
    "class TorchDataset(Dataset):\n",
    "    \"\"\"Map-style dataset\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = Tensor(X)\n",
    "        self.y = Tensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        import torch\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        X_i = self.X[idx]\n",
    "        y_i = self.y[idx]\n",
    "\n",
    "        # important: the dataset item must be returned as data,target\n",
    "        return X_i, y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "139000a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TorchDataset(train_data_T, train_labels_T)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False)\n",
    "test_set = TorchDataset(test_data_T, test_labels_T)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb4776",
   "metadata": {},
   "source": [
    "# Create Circuit and Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "956332c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In sampling mode, output_shape will be automatically inferred from the number of samples and interpret function, if provided.\n",
      "Cannot compute gradient operator! Continuing without gradients!\n"
     ]
    }
   ],
   "source": [
    "# Cicrcuito\n",
    "n_qubits = 4\n",
    "\n",
    "encoding = RawFeatureVector(16)\n",
    "encoding_ZZ = ZZFeatureMap(feature_dimension=n_qubits, reps=2)\n",
    "\n",
    "ansatz = EfficientSU2(n_qubits, \n",
    "                      entanglement='full', \n",
    "                      reps=4, \n",
    "                      insert_barriers=True, \n",
    "                      name=\"U(\\u03B8)\", \n",
    "                      parameter_prefix=\"\\u03B8\")\n",
    "\n",
    "qc = QuantumCircuit(n_qubits)\n",
    "qc.append(encoding, range(n_qubits))\n",
    "qc.append(ansatz, range(n_qubits))\n",
    "qc.decompose().draw(output=\"text\")\n",
    "\n",
    "parity = lambda x: \"{:b}\".format(x).count(\"1\") % 2\n",
    "output_shape = 2  \n",
    "qnn = CircuitQNN(circuit=qc,\n",
    "                 input_params=encoding.parameters,\n",
    "                 weight_params=ansatz.parameters,\n",
    "                 interpret=parity,\n",
    "                 output_shape=output_shape,\n",
    "                 sampling=True,\n",
    "                 input_gradients=True, \n",
    "                 quantum_instance=quantum_instance)\n",
    "\n",
    "initial_parameters = np.random.random(ansatz.num_parameters)\n",
    "\n",
    "model = TorchConnector(qnn, initial_parameters)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.1)\n",
    "loss_func = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c88a54",
   "metadata": {},
   "source": [
    "# Create Torch Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c5ec82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(out, target):\n",
    "    from numpy import sign\n",
    "    score = 0\n",
    "    if sign(out.item()) == target.item():\n",
    "        score = 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, optimizer, and loss\n",
    "optimizer = Adam(model.parameters())\n",
    "f_loss = CrossEntropyLoss()  # Our output will be in the [0,1] range\n",
    "\n",
    "# Start training\n",
    "model.train()\n",
    "\n",
    "# Define LBFGS closure method (explained in previous section)\n",
    "def closure():\n",
    "    optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "    loss = f_loss(model(train_data_T), train_labels_T)  # Calculate loss\n",
    "    loss.backward()  # Backward pass\n",
    "\n",
    "    print(loss.item())  # Print loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1729a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3349,  0.3954,  0.0420, -2.1485,  0.7837],\n",
      "        [-1.6283,  0.5872, -0.7256,  0.7232, -0.6321],\n",
      "        [-1.1023, -1.5871, -0.9791, -2.1348,  0.6405]], requires_grad=True)\n",
      "tensor([[0.1085, 0.1157, 0.0755, 0.6382, 0.0621],\n",
      "        [0.1574, 0.0994, 0.4204, 0.0558, 0.2671],\n",
      "        [0.0378, 0.1449, 0.2533, 0.1175, 0.4464]])\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c16550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train execution time:  11498.90387415886\n",
      "id:  cafnv75toase3u9lgiug\n",
      "execution time:  159.3931486606598\n",
      "score:  0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "torch_runtime_client_TW_MSE = TorchRuntimeClient(\n",
    "    provider=provider,\n",
    "    model=model1,\n",
    "    optimizer=optimizer1,\n",
    "    loss_func=loss_func1,\n",
    "    epochs=20,\n",
    "    backend=backend,\n",
    ")\n",
    "    \n",
    "fit_result_TW_MSE = torch_runtime_client_TW_MSE.fit(train_loader=train_loader)\n",
    "print(\"train execution time: \", fit_result_TW_MSE.execution_time)\n",
    "\n",
    "score_result = torch_runtime_client_TW_MSE.score(data_loader=test_loader, score_func=score_func)\n",
    "print(\"id: \", score_result.job_id)\n",
    "print(\"execution time: \", score_result.execution_time)\n",
    "print(\"score: \", score_result.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba58612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "fit_result_TW_MSE.model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc637d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "## ERRO, mt provavelmente e o encode\n",
    "fit_result_CQNN_CEL = torch_runtime_client_CQNN_CEL.fit(train_loader=train_loader, val_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf166b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "# In this example, we use the same data loader for the prediction as well\n",
    "predict_result = torch_runtime_client_TW_MSE.predict(data_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2f52d2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_result\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_state_dict)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_result' is not defined"
     ]
    }
   ],
   "source": [
    "print(predict_result.model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6688a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping\n",
    "def score_func(out, target):\n",
    "    from numpy import sign\n",
    "    score = 0\n",
    "    print(\"out: \", out, type(out))\n",
    "    print(\"target: \", target)\n",
    "    if sign(out.item()) == target.item():\n",
    "        score = 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping\n",
    "# data_loader = train_loader\n",
    "\n",
    "score_result = torch_runtime_client_TW_MSE.score(data_loader=train_loader, score_func=score_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd530d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "print(\"id: \", score_result.job_id)\n",
    "print(\"execution time: \", score_result.execution_time)\n",
    "print(\"score: \", score_result.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74197d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "## data_laoder = test_loader\n",
    "\n",
    "score_result = torch_runtime_client.score(data_loader=test_loader, score_func=score_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "print(\"id: \", score_result.job_id)\n",
    "print(\"execution time: \", score_result.execution_time)\n",
    "print(\"score: \", score_result.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efbe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "torch_runtime_client2 = TorchRuntimeClient(\n",
    "    provider=provider,\n",
    "    model=model1,\n",
    "    optimizer=optimizer2,\n",
    "    loss_func=loss_func2,\n",
    "    epochs=50,\n",
    "    backend=backend,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "fit_result2 = torch_runtime_client2.fit(train_loader=train_loader, val_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b498b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "predict_result = torch_runtime_client2.predict(data_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0233fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "print(type(fit_result2.model_state_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "fit_result2.model_state_dict\n",
    "fit_result2.val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c52eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb696c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "print(predict_result.val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18302a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
